{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5d395496",
   "metadata": {},
   "source": [
    "**Q1.What does one mean by the term \"machine learning\"?**\n",
    "\n",
    "Ans:- Machine Learning is a subset of AI(Artificial Intelligence). It has provided data statistics tools to build intelligent computer systems that can learn from available databases.\n",
    "**************************************************************************************************************************"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2617ef0",
   "metadata": {},
   "source": [
    "**Q2.Can you think of 4 distinct types of issues where it shines?**\n",
    "    \n",
    "Ans:- Machine learning algorithms have had good results on problems such has spam detection in mail, Product Recommend System, Customer segmentation, Customer service automation etc.\n",
    "**************************************************************************************************************************"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a406aab",
   "metadata": {},
   "source": [
    "**Q3.What is a labeled training set, and how does it work?**\n",
    "\n",
    "Ans:- Labeled data is a group of samples that have been tagged with one or more labels. Supervised learning uses labeled training data.\n",
    "**************************************************************************************************************************"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9f2c052",
   "metadata": {},
   "source": [
    "**Q4.What are the two most important tasks that are supervised?**\n",
    "\n",
    "Ans:- In supervised machine learning two most important task is Regression and Classification.In regression our prediction is a continuous value and in classification our output is 0 or 1.\n",
    "**************************************************************************************************************************"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0472194c",
   "metadata": {},
   "source": [
    "**Q5.Can you think of four examples of unsupervised tasks?**\n",
    "\n",
    "Ans:- Common unsupervised tasks include clustering, visualization, dimensionality reduction, and association rule learning\n",
    "**************************************************************************************************************************"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "031f35d9",
   "metadata": {},
   "source": [
    "**Q6.State the machine learning model that would be best to make a robot walk through various unfamiliar terrains?**\n",
    "\n",
    "Ans:- The best Machine Learning algorithm to allow a robot to walk in unknown terrain is Reinforced Learning, where the robot can learn from response of the terrain to optimize itself\n",
    "**************************************************************************************************************************"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1feacf0e",
   "metadata": {},
   "source": [
    "**Q7.Which algorithm will you use to divide your customers into different groups?**\n",
    "\n",
    "Ans:- Clustering algorithm is a technique that assists customer segmentation which is a process of classifying similar customers into the same segment.\n",
    "**************************************************************************************************************************"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61b50155",
   "metadata": {},
   "source": [
    "**Q8:- Will you consider the problem of spam detection to be a supervised or unsupervised learning problem?**\n",
    "\n",
    "Ans:- Spam detection is Supervised learning problem. Where the algorithm is trained using labeled data and check mail is \"spam\" or \"not spam\".\n",
    "**************************************************************************************************************************"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acd74ffc",
   "metadata": {},
   "source": [
    "**Q9.What is the concept of an online learning system?**\n",
    "\n",
    "Ans:- An online learning system, also known as incremental learning or streaming learning, is a machine learning framework that allows the algorithm to learn continuously from a stream of incoming data in real-time.\n",
    "\n",
    "The concept of an online learning system is particularly useful in scenarios where the data is constantly changing, and it may not be feasible or efficient to store and process the entire dataset for batch learning. Instead, the algorithm processes new data instances one at a time or in small batches and updates the model accordingly.\n",
    "\n",
    "Online learning systems are commonly used in applications such as real-time prediction, fraud detection, recommendation systems, and anomaly detection\n",
    "**************************************************************************************************************************"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "016cd9e2",
   "metadata": {},
   "source": [
    "**Q10.What is out-of-core learning, and how does it differ from core learning?**\n",
    "\n",
    "Ans:- Out-of-core learning, also known as external memory learning or disk-based learning, is a technique used in machine learning to handle datasets that are too large to fit into the available memory (RAM) of a computer. It is specifically designed to address the limitations of memory-bound systems by processing data directly from disk storage.\n",
    "\n",
    "in-core learning, refers to traditional machine learning approaches where the entire dataset is loaded into memory for processing. This assumes that the dataset can comfortably fit within the memory limits of the system.\n",
    "\n",
    "The key difference between out-of-core learning and core learning lies in how the data is accessed and processed during training. In core learning, the entire dataset is loaded into memory, enabling fast access to the data and efficient processing using algorithms designed for in-memory computations. This approach works well when the dataset size is manageable and fits within the memory constraints.\n",
    "\n",
    "On the other hand, out-of-core learning handles large datasets by reading and processing data in smaller manageable chunks or batches, which are loaded from disk sequentially. Only a fraction of the data is loaded into memory at a time, allowing the algorithm to operate within the memory limits. Once a batch is processed, it is typically discarded to make room for the next batch, minimizing the memory footprint.\n",
    "**************************************************************************************************************************"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22d324e9",
   "metadata": {},
   "source": [
    "**Q11.What kind of learning algorithm makes predictions using a similarity measure?**\n",
    "\n",
    "Ans:- The learning algorithm that makes predictions using a similarity measure is called instance-based learning or lazy learning.\n",
    "\n",
    "The key idea behind instance-based learning is that similar instances tend to have similar output values. When a new instance is presented for prediction, the algorithm calculates the similarity between the new instance and the stored training instances using a similarity measure, such as Euclidean distance, cosine similarity, or edit distance. Based on the closest or most similar training instances, the algorithm makes predictions by considering the labels or values associated with those instances.\n",
    "\n",
    "The most well-known instance-based learning algorithm is the k-nearest neighbors (KNN) algorithm. In KNN, the algorithm stores the entire training dataset in memory and predicts the label or value of a new instance based on the labels or values of its k-nearest neighbors in the training data, where k is a user-defined parameter. The similarity measure, such as Euclidean distance, is used to determine the nearest neighbors."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53d20fff",
   "metadata": {},
   "source": [
    "**Q12.What's the difference between a model parameter and a hyperparameter in a learning algorithm?**\n",
    "\n",
    "Ans:- Model parameters are internal variables learned by the algorithm during training, while hyperparameters are external configuration settings that determine the behavior and characteristics of the learning algorithm itself. Model parameters are specific to the chosen model and its architecture, while hyperparameters affect how the learning algorithm operates and can be tuned to optimize the model's performance on a specific task.\n",
    "**************************************************************************************************************************"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b43c8f65",
   "metadata": {},
   "source": [
    "**Q13.What are the criteria that model-based learning algorithms look for? What is the most popular method they use to achieve success? What method do they use to make predictions?**\n",
    "\n",
    "Ans:- Model-based learning algorithms aim to find a model or function that can accurately represent the underlying patterns and relationships in the data. The criteria that model-based learning algorithms typically look for are:\n",
    "\n",
    "The model should provide a good fit to the training data, meaning it should capture the patterns and relationships present in the data as accurately as possible.\n",
    "The model should generalize well to unseen or test data, meaning it should perform well on new data points that were not used during training. \n",
    "\n",
    "To achieve success, model-based learning algorithms commonly use optimization techniques to optimize the model parameters and find the best fit to the training data. The most popular method used is iterative optimization, where the algorithm updates the model parameters iteratively based on the gradient of the loss function with respect to the parameters. Gradient-based optimization algorithms, such as gradient descent or its variants (e.g., stochastic gradient descent), are widely used to minimize the loss function and optimize the model's parameters.\n",
    "\n",
    "The learned model is then used to make predictions on new instances based on the learned patterns and relationships in the data.The specific method used for prediction depends on the chosen model. For example, in linear regression, the model predicts the output based on a linear combination of the input features and the learned coefficients. In decision trees, the model follows the decision rules defined by the tree structure to assign a class or value to the new instance.\n",
    "**************************************************************************************************************************"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c9a11c2",
   "metadata": {},
   "source": [
    "**Q14.Can you name four of the most important Machine Learning challenges?**\n",
    "\n",
    "Ans:-four important challenges commonly encountered in machine learning:\n",
    "\n",
    "Overfitting: This leads to poor generalization, where the model performs well on the training data but fails to make accurate predictions on unseen data.\n",
    "\n",
    "Data Quality and Quantity: The quality and quantity of data have a substantial impact on the performance of machine learning models. Insufficient or noisy data can lead to biased or unreliable predictions. Data collection, preprocessing, and ensuring data representativeness are crucial challenges in machine learning. Additionally, dealing with imbalanced datasets, missing values, or outliers poses further challenges in model training and evaluation.\n",
    "\n",
    "Feature Engineering and Selection: Feature engineering involves selecting or creating relevant and informative features from raw data to facilitate learning and improve model performance. Choosing the right set of features is often a challenging and time-consuming process that requires domain knowledge and expertise.\n",
    "\n",
    "Interpretability and Explainability: Many machine learning models, such as deep neural networks, are often considered black-box models, meaning their decision-making processes are not easily interpretable or explainable to humans. Interpreting and understanding the inner workings of complex models is a significant challenge, particularly in domains where interpretability and explainability are critical, such as healthcare or finance.\n",
    "**************************************************************************************************************************"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd6f0390",
   "metadata": {},
   "source": [
    "**Q15.What happens if the model performs well on the training data but fails to generalize the results to new situations? Can you think of three different options?**\n",
    "\n",
    "Ans:- If a model performs well on the training data but fails to generalize to new situations, it indicates a problem with the model's ability to capture the underlying patterns and make accurate predictions on unseen data. Here are three different options to consider in such a scenario:\n",
    "\n",
    "Overfitting: Overfitting occurs when a model becomes too complex and fits the noise or irrelevant details in the training data. In this case, the model has memorized the training examples instead of learning the underlying patterns. To address overfitting, you can consider reducing the complexity of the model, adding regularization techniques (such as L1 or L2 regularization), increasing the amount of training data, or using techniques like cross-validation to better estimate model performance on unseen data.\n",
    "\n",
    "Insufficient or Biased Training Data: If the training data is limited or not representative of the true population, the model may not be able to generalize well.\n",
    "\n",
    "Lack of Feature Relevance or Complexity: The features used by the model may not adequately capture the relevant information for making accurate predictions in new situations. It is crucial to carefully select or engineer features that are informative and meaningful for the problem at hand. Exploring alternative feature representations, conducting feature importance analysis, or using feature selection techniques can help identify more relevant features and improve the model's ability to generalize.\n",
    "**************************************************************************************************************************"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15aa7233",
   "metadata": {},
   "source": [
    "**Q16.What exactly is a test set, and why would you need one?**\n",
    "\n",
    "Ans:-When we want to know how well our model generalizes to new cases we prefer to use a test set instead of actually deploying the system. The test set should only be used for final model evaluation and not for any training or model selection decisions.\n",
    "\n",
    "By using a test set, we can measure important metrics such as accuracy, precision, recall, F1 score, or other evaluation metrics that provide a quantitative assessment of the model's performance on unseen data. It helps in comparing different models, tuning hyperparameters, and making informed decisions about the model's suitability for real-world deployment.\n",
    "**************************************************************************************************************************"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34bffcb5",
   "metadata": {},
   "source": [
    "**Q17.What is a validation set's purpose?**\n",
    "\n",
    "Ans:-Let's say we have a linear model and we want to perform some hyperparameter tuning to reduce the generalization error. One way to do this 100 different models with 100 different hyperparameter values using the training set and finding the generalization error with the test set. You find the best hyperparameter value gives you 5% generalization error.\n",
    "So you launch the model into production and find you're seeing 15% generalization error. This isn't going as expected. What happened?\n",
    "\n",
    "The problem is that for each iteration of hyperparameter tuning, you measured the generalization error then updated the model using the same test set. In other words, your produced the best generalization error for the test set. The test set no longer represents cases the model hasn't seen before.\n",
    "\n",
    "A common solution to this problem is to have a second holdout set called the validation set. You train multiple models with various hyperparameters using the training set, you select the model and hyperparameters that perform best on the validation set, and when you are happy about your model you run a single final test against the test set to get an estimate of the generalization error.\n",
    "**************************************************************************************************************************"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6332eb1a",
   "metadata": {},
   "source": [
    "**Q18.What precisely is the train-dev kit, when will you need it, how do you put it to use?**\n",
    "\n",
    "Ans:- There is no specific concept or widely recognized term called \"train-dev kit\" in machine learning. Instead, it is important to understand the purpose and usage of the training set and the development/validation set. The training set is used for model parameter estimation, while the development/validation set is used for model evaluation, hyperparameter tuning, and model selection. These datasets play crucial roles in the iterative process of training and refining machine learning models.\n",
    "**************************************************************************************************************************"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38c33384",
   "metadata": {},
   "source": [
    "**Q19.What could go wrong if you use the test set to tune hyperparameters?**\n",
    "\n",
    "Ans:- If you use the test set to tune hyperparameters, several issues can arise, compromising the reliability and validity of the final evaluation of your model. Here are some of the problems that can occur:\n",
    "\n",
    "Bias in Performance Estimation: The test set is meant to provide an unbiased assessment of the model's generalization performance on unseen data. However, if you repeatedly evaluate and tweak your model based on its performance on the test set, the hyperparameters might become tailored to this specific set of data. Consequently, the model's performance on the test set will no longer reflect its ability to generalize to new, unseen instances.\n",
    "\n",
    "Overfitting to the Test Set: When hyperparameters are tuned using the test set, the model's hyperparameters become specifically optimized for that particular dataset. This can lead to overfitting to the test set, where the model becomes specifically tailored to perform well on the test set but fails to generalize to new data. Essentially, the model starts to memorize the test set instead of learning the underlying patterns and relationships.\n",
    "\n",
    "Lack of Evaluation on Unseen Data: The purpose of the test set is to provide an unbiased evaluation of the model's performance on unseen data. By using the test set for hyperparameter tuning, you no longer have a reliable measure of how well the model will perform on new, real-world instances. This can lead to unrealistic expectations about the model's performance and potential issues when deploying the model in practice.\n",
    "\n",
    "To mitigate these problems, it is crucial to have a separate validation set or development set for hyperparameter tuning. This set should be kept completely independent of the test set and used solely for evaluating different hyperparameter configurations and selecting the best-performing model. By reserving the test set for the final evaluation after hyperparameter tuning, you ensure a more reliable assessment of the model's generalization performance on unseen data."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
